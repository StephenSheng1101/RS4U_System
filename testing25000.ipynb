{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMcHbIig7XrXPFCqQ1y67AQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/StephenSheng1101/RS4U_System/blob/main/testing25000.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "b7NTgjeveK0g"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Yelp dataset (replace 'path_to_yelp_dataset.csv' with the actual path to your Yelp dataset file)\n",
        "filename = 'yelp_review.csv'"
      ],
      "metadata": {
        "id": "cnGK69aCicdH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read CSV file\n",
        "df = pd.read_csv(filename, encoding='utf-8', on_bad_lines=\"skip\", engine=\"python\")\n",
        "# Limit the dataset size to 1000 rows\n",
        "df = df.head(100)\n",
        "\n",
        "# Assuming your dataset has 'stars' as the rating and 'text' as the review text\n",
        "data = {'text': df['text'].values, 'stars': df['stars'].values}\n",
        "\n",
        "# Map star ratings to sentiment classes (positive, negative, neutral, etc.)\n",
        "# For simplicity, we'll consider ratings 1 and 2 as negative, 3 as neutral, and 4 and 5 as positive\n",
        "data['sentiment'] = pd.cut(data['stars'], bins=[0, 2, 3, 5], labels=['negative', 'neutral', 'positive'])\n",
        "\n",
        "# Convert the dictionary to a Pandas DataFrame\n",
        "df_data = pd.DataFrame(data)"
      ],
      "metadata": {
        "id": "d4aWAm9RijBL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into training, validation, and test sets\n",
        "train_data, test_data = train_test_split(df_data, test_size=0.2, random_state=42)\n",
        "\n",
        "# If you want to further split for validation, you can do the following\n",
        "valid_data, test_data = train_test_split(test_data, test_size=0.5, random_state=42)\n"
      ],
      "metadata": {
        "id": "Mv2avxPbikfw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BERT tokenizer and model (using bert-base-cased)\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-cased', num_labels=3)  # 3 classes: negative, neutral, positive\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2oLIoVKgiksL",
        "outputId": "675a9236-b005-40e7-d3a2-2ee81f5828fc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a custom dataset\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "        self.label_mapping = {'negative': 0, 'neutral': 1, 'positive': 2}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts.iloc[idx]\n",
        "        label = torch.tensor(self.label_mapping[self.labels.iloc[idx]], dtype=torch.long)\n",
        "\n",
        "        # Tokenize the text\n",
        "        tokens = self.tokenizer(\n",
        "            text,\n",
        "            max_length=self.max_length,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': tokens['input_ids'].squeeze(),\n",
        "            'attention_mask': tokens['attention_mask'].squeeze(),\n",
        "            'label': label\n",
        "        }\n"
      ],
      "metadata": {
        "id": "ukETYDyIisFY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize and create DataLoader\n",
        "def create_dataloader(data, tokenizer, max_length=512, batch_size=32):\n",
        "    dataset = CustomDataset(texts=data['text'], labels=data['sentiment'], tokenizer=tokenizer, max_length=max_length)\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "    return dataloader\n",
        "\n"
      ],
      "metadata": {
        "id": "xZhVM_67isHA"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = create_dataloader(train_data, tokenizer)\n",
        "valid_dataloader = create_dataloader(valid_data, tokenizer)\n",
        "test_dataloader = create_dataloader(test_data, tokenizer)"
      ],
      "metadata": {
        "id": "SQYKIj2UisKP"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "criterion = CrossEntropyLoss()\n",
        "\n",
        "num_epochs = 3\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in train_dataloader:\n",
        "        inputs = {key: val.to(device) for key, val in batch.items()}\n",
        "\n",
        "        # Change here\n",
        "        outputs = model(inputs['input_ids'], attention_mask=inputs['attention_mask'], labels=inputs['label'])\n",
        "        loss = outputs.loss\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    # Calculate average training loss\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for batch in valid_dataloader:\n",
        "            inputs = {key: val.to(device) for key, val in batch.items()}\n",
        "            outputs = model(inputs['input_ids'], attention_mask=inputs['attention_mask'])\n",
        "            logits = outputs.logits\n",
        "            preds = torch.argmax(logits, dim=1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(inputs['label'].cpu().numpy())\n",
        "\n",
        "    # Calculate accuracy on validation set\n",
        "    accuracy_valid = accuracy_score(all_labels, all_preds)\n",
        "\n",
        "    print(f'Epoch {epoch + 1}/{num_epochs}, Avg Train Loss: {avg_train_loss:.4f}, Validation Accuracy: {accuracy_valid:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzv5fB_risL6",
        "outputId": "c4cd084e-998f-4a95-f7b0-1d34f90df875"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing on the original model trained using the test set\n",
        "model.eval()\n",
        "all_preds_test = []\n",
        "all_labels_test = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_dataloader:\n",
        "        inputs = {key: val.to(device) for key, val in batch.items()}\n",
        "        outputs = model(inputs['input_ids'], attention_mask=inputs['attention_mask'])\n",
        "        logits = outputs.logits\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "        all_preds_test.extend(preds.cpu().numpy())\n",
        "        all_labels_test.extend(inputs['label'].cpu().numpy())\n",
        "\n",
        "# Calculate accuracy, precision, recall, and f1 score on the test set\n",
        "accuracy_test = accuracy_score(all_labels_test, all_preds_test)\n",
        "precision = precision_score(all_labels_test, all_preds_test, average='weighted')\n",
        "recall = recall_score(all_labels_test, all_preds_test, average='weighted')\n",
        "f1 = f1_score(all_labels_test, all_preds_test, average='weighted')\n",
        "print(f'Accuracy (Original Model): {accuracy_test:.4f}')\n",
        "print(f'Precision (Original Model): {precision:.4f}')\n",
        "print(f'Recall (Original Model): {recall:.4f}')\n",
        "print(f'F1 Score (Original Model): {f1:.4f}')\n",
        "\n",
        "# Confusion matrix on the test set\n",
        "conf_matrix = confusion_matrix(all_labels_test, all_preds_test)\n",
        "print('Confusion Matrix (Original Model):')\n",
        "print('               Predicted Positive Predicted Negative')\n",
        "print(f'Actual Positive      {conf_matrix[0, 0]}                 {conf_matrix[0, 1]}')\n",
        "print(f'Actual Negative      {conf_matrix[1, 0]}                 {conf_matrix[1, 1]}')\n",
        "\n",
        "\n",
        "# Save the results to a text file\n",
        "results_file = 'results_original.txt'\n",
        "with open(results_file, 'w') as file:\n",
        "    file.write(f'Test Accuracy (Original Model): {accuracy_test:.4f}\\n')\n",
        "    file.write(f'Precision (Original Model): {precision:.4f}\\n')\n",
        "    file.write(f'Recall (Original Model): {recall:.4f}\\n')\n",
        "    file.write(f'F1 Score (Original Model): {f1:.4f}\\n')\n",
        "    file.write('Confusion Matrix (Original Model):\\n')\n",
        "    file.write('               Predicted Positive Predicted Negative\\n')\n",
        "    file.write(f'Actual Positive      {conf_matrix[0, 0]}                 {conf_matrix[0, 1]}\\n')\n",
        "    file.write(f'Actual Negative      {conf_matrix[1, 0]}                 {conf_matrix[1, 1]}\\n')\n"
      ],
      "metadata": {
        "id": "dNVsyQYKisO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model\n",
        "trained_model_path = 'RS4U_model'\n",
        "model.save_pretrained(trained_model_path)\n"
      ],
      "metadata": {
        "id": "5LmJNyRiisQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the saved model\n",
        "loaded_model = BertForSequenceClassification.from_pretrained(trained_model_path, num_labels=3)\n",
        "loaded_model.to(device)\n",
        "\n"
      ],
      "metadata": {
        "id": "tVdMxuM-isUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5 Review Predictions using the saved model\n",
        "reviews_to_predict = [\n",
        "    \"This product is amazing! I love it.\",\n",
        "    \"The quality is terrible, and I regret buying this.\",\n",
        "    \"Neutral review. Not impressed, but not disappointed either.\",\n",
        "    \"Best purchase ever! I highly recommend it.\",\n",
        "    \"Waste of money. The worst product I have ever bought.\"\n",
        "]\n",
        "\n",
        "# Tokenize and predict sentiment for the 5 reviews using the saved model\n",
        "loaded_model.eval()\n",
        "predictions = []\n",
        "\n",
        "for review in reviews_to_predict:\n",
        "    inputs = tokenizer(review, return_tensors='pt')\n",
        "    inputs = {key: val.to(device) for key, val in inputs.items()}\n",
        "    outputs = loaded_model(inputs['input_ids'], attention_mask=inputs['attention_mask'])\n",
        "    logits = outputs.logits\n",
        "    predicted_class = torch.argmax(logits, dim=1).item()\n",
        "    predictions.append(predicted_class)\n",
        "\n",
        "print(\"Predictions for the 5 reviews:\")\n",
        "# Save the predictions and percentages to a file\n",
        "results_file_saved_model = '5review_results_saved_model.txt'\n",
        "with open(results_file_saved_model, 'w') as file:\n",
        "    file.write(\"Predictions for the 5 reviews using the saved model:\\n\")\n",
        "    for review, prediction in zip(reviews_to_predict, predictions):\n",
        "        file.write(f\"Review: {review}\\nPredicted Sentiment: {prediction}\\n\")\n",
        "        print(f\"Review: {review}\\nPredicted Sentiment: {prediction}\\n\")\n",
        "\n",
        "        # Calculate percentage of negative, positive, and neutral for each review\n",
        "        total_count = len(predictions)\n",
        "        negative_percentage = (predictions.count(0) / total_count) * 100\n",
        "        neutral_percentage = (predictions.count(1) / total_count) * 100\n",
        "        positive_percentage = (predictions.count(2) / total_count) * 100\n",
        "\n",
        "        print(f\"Percentage of Negative: {negative_percentage:.2f}%\")\n",
        "        print(f\"Percentage of Neutral: {neutral_percentage:.2f}%\")\n",
        "        print(f\"Percentage of Positive: {positive_percentage:.2f}%\")\n",
        "        print()\n",
        "\n",
        "        file.write(f\"Percentage of Negative: {negative_percentage:.2f}%\\n\")\n",
        "        file.write(f\"Percentage of Neutral: {neutral_percentage:.2f}%\\n\")\n",
        "        file.write(f\"Percentage of Positive: {positive_percentage:.2f}%\\n\")\n",
        "        file.write(\"\\n\")\n",
        "\n",
        "print(\"Results saved to:\", results_file_saved_model)\n",
        "\n"
      ],
      "metadata": {
        "id": "VKb72rS6jNFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uvIVmmc5jNHC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ewCwHPgEjNKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i8WZ7nuojNL5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}